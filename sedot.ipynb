{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Y7EiJSZYADd",
        "outputId": "47f049bd-620f-47d4-8475-db196302757b"
      },
      "source": [
        "# We'll be using these libraries to peform our sentiment analysis, so first we install them\n",
        "!pip install tweepy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tweepy in /usr/local/lib/python3.7/dist-packages (3.10.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy) (1.15.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy) (1.3.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy) (1.24.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy) (1.7.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_q6rOJ8_Ok6W"
      },
      "source": [
        "from google.colab import drive\n",
        "import tweepy\n",
        "import csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUx44wcEOtdZ"
      },
      "source": [
        "# Adding keys necessary to use Twitter API\n",
        "consumer_key = 'fj9vxzxn3UAwOdmuz4btMWV1V'\n",
        "consumer_secret = 'uZgwB0LHjLbfJAfEUF3SOaatuZ35sE9f2iSuYN1MVnsLKQ9UbR'\n",
        "access_token = '1314611076508524544-k02lPsjJBSYzfkgezjg81NOO3Aqo3r'\n",
        "access_token_secret = 'hR0ULr4LkXP0AnlnqS3tUcoE4ZeSHQbNbKosVK6mqBD35'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0p0GtxMQnlm",
        "outputId": "c689ba02-ebfd-4700-aec5-183b7266540c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUCJodhyOwnI"
      },
      "source": [
        "# auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "# auth.set_access_token(access_token, access_token_secret)\n",
        " \n",
        "# api = tweepy.API(auth)\n",
        "# csvFile = open('/content/drive/My Drive/Colab Notebooks/result-12.csv', 'a')\n",
        "# #Use csv writer\n",
        "# csvWriter = csv.writer(csvFile)\n",
        " \n",
        "# tweets = api.search('@Indihome', count=100)\n",
        " \n",
        "# for tweet in tweets:\n",
        "#     csvWriter.writerow([tweet.text.encode('utf-8')])\n",
        " \n",
        "# csvFile.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQ18SaYlPzWe"
      },
      "source": [
        "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "\n",
        "api = tweepy.API(auth)\n",
        "\n",
        "csvFile = open('/content/drive/My Drive/Colab Notebooks/data-14.csv', 'a')\n",
        "#Use csv writer\n",
        "csvWriter = csv.writer(csvFile)\n",
        "\n",
        "for tweet in tweepy.Cursor(api.search, lang=\"id\",  q=\"@IndiHomeCare pemasangan\",since=\"2021-04-6\", tweet_mode=\"extended\").items(200):\n",
        "        if not (hasattr(tweet, 'retweeted_status')): # to avoid retweet\n",
        "                csvWriter.writerow([tweet.user.screen_name, tweet.id, # saving only user name and tweet\n",
        "                                    tweet.full_text.replace(\"\\n\", \"\")])\n",
        "\n",
        "        # if (hasattr(tweet, 'retweeted_status')): # if you wanna also the retweets\n",
        "        #         csvWriter.writerow([tweet.id\n",
        "        #                             tweet.retweeted_status.full_text.replace(\"\\n\", \"\")])\n",
        "\n",
        "csvFile.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbWFF0ImZydC"
      },
      "source": [
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "clf_svm = svm.LinearSVC()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train_tfidf, training_data.flag, test_size=0.20, random_state=42)\n",
        "clf_svm.fit(X_train_tfidf, training_data.flag)\n",
        "# SAVE MODEL\n",
        "pickle.dump(clf_svm, open(\"svm.pkl\", \"wb\"))\n",
        "# Predicting the output\n",
        "predicted = clf_svm.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
